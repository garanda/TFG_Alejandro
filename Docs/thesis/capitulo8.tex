\chapter{Conclusiones y Trabajo Futuro.}\label{cap:capitulo8}

En este capítulo se explican las conclusiones finales de este trabajo, y se comentarán algunas líneas de trabajo futuro.

\section{Conclusiones.}

En este trabajo se ha presentado un método para conciliar el conocimiento global de un Sistema de Etiquetado (SE). Este método está basado en la tecnología multiagente, y se ha llevado a cabo con una implementación realizada en JADE (\cite{jade}). El sistema de etiquetado elegido ha sido Delicious (\cite{delicious}); concretamente se ha elegido un subconjunto de datos de Delicious, obtenido a partir de la etiqueta {\bf haskell} (ver capítulo~\ref{cap:capitulo5}).

La solución realizada (ver capítulo~\ref{cap:capitulo6}) es un SMA basado en negociación entre agentes, de forma que a medida que transcurre la ejecución de este SMA, los agentes (que representa a los usuarios del SE) negocian con otros agentes con los que quieren conciliar su conocimiento. Esto va generando diferentes contextos conciliados entre pares de usuarios, que representan el conocimiento común. Estos contextos se almacenan en una base de datos, guardando los identificadores de ambos usuarios, los objetos (enlaces) y sus atributos (etiquetas) que forman parte del contexto, y también el número de objetos que comparten ambos usuarios (que en este trabajo hemos llamado \emph{{\bf umbral}}). Es trivial obtener una representación de este contexto utilizando las herramientas de ConExp (\cite{conexp}), nos centraremos en obtener el Retículo de Conceptos (formales) y las Bases Stem que representan este Contexto común.

Finalmente, se han tomado muestras de los resultados obtenidos (ver capítulo~\ref{cap:capitulo7}), en los que se observa una relación inversa entre el umbral (o número de objetos que dos usuarios comparten) y el número de conciliaciones que se producen para dicho umbral; es decir, cuanto mayor es el umbral, existen menos parejas de usuarios para conciliar su conocimiento. Sin embargo, la relación es directa entre el umbral y el tamaño de los contextos, medido en el número de objetos y atributos generado, y en el número de conceptos e implicaciones obtenidos; es decir, a medida que crece el umbral, los contextos generados, aunque sean menos, son más ricos, pues tienen un mayor número de objetos (enlaces), atributos (etiquetas), conceptos generados e implicaciones obtenidas. Estos resultados se justifican trivialmente porque:
\begin{itemize}
	\item A medida que se aumenta el umbral, el número de conciliaciones es menor, puesto que habrá un mayor número de pares de usuarios que compartan pocos enlaces.
	\item A medida que se aumenta el umbral, el tamaño de los contextos conciliados es mayor, puesto que si un par de usuarios comparte muchos enlaces es previsible que también tengan un lenguaje común (o número de atributos comunes) grande (aunque no siempre se da esta circunstancia), y por tanto, también es previsible que la conciliación genere un gran número de sugerencias. El resultado es, por tanto, un contexto conciliado grande.
\end{itemize}

Es interesante destacar que partiendo de un conjunto de datos relativamente grande (compuesto por 4259 usuarios, 2427 etiquetas, 3028 enlaces y 45079 tuplas), se producen un total de 663 conciliaciones con $umbral \geq 3$; es decir con usuarios que comparten al menos 3 enlaces.

De este total, 561 de ellas se realizan cuando únicamente comparten 3 enlaces (y no más); esto representa el $84.62$\% del total de conciliaciones. Además, es interesante ver las características de estos contextos conciliados que tiene de media\footnote{Se ha aproximado al límite entero superior} 29 objetos, 9 atributos, 6 conceptos y 8 implicaciones. Aunque el número de objetos (y relativamente también el número de atributos) es suficientemente grande, los contextos generados son muy \emph{pobres} ya que el número de conceptos e implicaciones es muy bajo. Hay que recordar que en el ejemplo que se ilustraba en el capítulo~\ref{cap:capitulo2}, con un contexto de únicamente 5 objetos y 3 atributos (mucho más pequeño que en este caso) se obtiene 6 conceptos (que ya supera la media obtenida) y 1 implicación. En conclusión, la mayoría de los contextos obtenidos son muy pobres.

De las 102 conciliaciones restantes (conciliaciones entre usuarios que comparten 4 o más enlaces), que representan el $15.38$\% del total, 75 de ellas se producen cuando únicamente comparten 4 enlaces. Esto representa un $73.53$\% relativo, y un $11.31$\% total. De nuevo, vuelven a ser un número bastante grande en comparación con el número de conciliaciones para umbrales superiores. Sin embargo, poco a poco se comienza a observar una mejoría en cuanto a la calidad de los contextos obtenidos, que están formados, de media, por 53 objetos, 14 atributos, 8 conceptos y 15 implicaciones.

Finalmente hay que indicar que los cálculos totales para el conjunto completo de contextos conciliados obtienen, de media, contextos formados por 34 objetos, 10 atributos, 7 conceptos y 10 implicaciones. Estos números se sitúan precisamente entre los umbrales 3 y 4.

En conclusión, a medida que se reduce el umbral aumenta el número de conciliaciones, pero los contextos generados son más pobres. El umbral mínimo que se ha establecido en la implementación de este trabajo ha sido 3, debido a que: (1) apenas se conseguían contextos significativos; y (2) los problemas de implementación que conlleva la ejecución de un SMA con umbrales tan bajos, en los que tienen que convivir muchos agentes, y la mayoría de ellos tiene una carga computacional alta.

Por otra parte, es interesante destacar el criterio que se ha utilizado para seleccionar que pares de usuarios que realizan conciliación es el {\bf número de objetos que comparten}. Este criterio se ha tomado por decisión no sistemática debido a un análisis no formal, cuya conclusión es que si el propio algoritmo filtra un lenguaje común entre pares de usuarios (conjunto de atributos comunes), un buen criterio para seleccionar estos pares es elegir el número de objetos comunes. La justificación es que, previsiblemente, el contexto obtenido tenga un número de objetos aceptable, que podría ser más bajo si muchos objetos son filtrados por no estar etiquetados con ninguna etiqueta del lenguaje común. Normalmente, este caso se produce cuando comparten pocos objetos. Sin embargo, esto no deja de ser una previsión, por lo que existen casos excepcionales que no cumplen esta regla. En la sección siguiente, veremos algunas líneas de trabajo futuro en este sentido.

Por último, es interesante hacer mención a los umbrales que no se han ejecutado; es decir, 0\footnote{Entiéndase que $umbral=0$ si no comparten ningún enlace.}, 1 y 2. En estos casos, las soluciones obtenidas no merecen la pena para el esfuerzo que conlleva en tareas de implementación. Este trabajo pretendía estudiar analíticamente los resultados producidos por la Conciliación en un Sistema de Etiquetado, y para ello se ha elegido un conjunto de datos cuyo tamaño es pequeño en comparación con el volumen de datos de un SE real. Estos resultados son muy interesantes y establecen un campo de trabajo que puede favorecer la navegación semántica en sistemas basados en folksonomías. En cambio, es interesante hacer notar que el número de conciliaciones producidas para umbrales relativamente altos\footnote{Estos umbrales deben ser mayores con conjuntos de datos de mayor volumen.} es muy pequeño, consecuencia de que el conjunto de prueba tiene también un volumen de datos relativamente pequeño. Sin embargo, en sistemas reales donde el volumen de datos sea exponencialmente mayor, este número de conciliaciones también crecerá, y por tanto, nos enfrentaremos a los mismos problemas que con estos umbrales pequeños (0, 1 y 2). En el capítulo~\ref{cap:capitulo6}, se comentaron algunas soluciones de implementación para solventar estos aspectos, que se comentan de forma más específica en la siguiente sección.




\section{Trabajo futuro.}

En esta sección, vamos a distinguir algunas líneas de trabajo futuro, divididas en varios ámbitos de aplicación: Investigación, Implementación y Aplicación.

\subsection{Investigación.}

En este apartado, vamos a describir algunas líneas de investigación; ya sea bien porque no se conoce concretamente los resultados esperados introduciendo ciertos cambios en el sistema, o bien porque son consecuencia de los resultados ya obtenidos. Veamos estas líneas:

\begin{itemize}

	\item Se ha visto las diferentes conclusiones obtenidas según el criterio utilizado para elegir a los pares de usuarios. Sería interesante investigar el comportamiento del sistema en base a otros criterios. Se deduce un criterio muy simple que es precisamente seleccionar los pares en función del tamaño de su lenguaje común; es decir, del número de atributos comunes. También sería interesante restringir este lenguaje común a aquellas etiquetas que ambos usuarios usan en el mismo enlace. Por otra parte, también se pueden buscar criterios más complejos. En el grafo~\ref{fig:grafo42}, se expresaban las relaciones más importantes entre los usuarios más relevantes. Otras posibles criterios pueden estar basados en distancias entre nodos de este grafo, o comunidades de usuarios. En cualquier de los criterios anteriores, es interesante contrastar los resultados que se obtengan con los de este trabajo.

	\item Por ahora, sólo se ha implementado la Conciliación de conocimiento por pares de usuarios. Sin embargo, también se deduce una tarea que puede ser muy interesante: ¿cuál es el conocimiento compartido por un sistema completo, o por un grupo de usuarios? En esta línea, sería interesante investigar cuales son los resultados si se concilia varios contextos conciliados, para obtener el conocimiento conciliado de múltiples usuarios.

	\item En la misma línea del punto anterior, en \cite{jaschke} se introducen los \emph{triconceptos} como modelo de conceptualizaciones compartidas por grupos de usuarios. Este elemento podría ser interesante para trabajar con el conocimiento conciliado de todos ellos. 

	\item En el ámbito del Análisis Formal de Conceptos, sería interesar investigar nuevas técnicas para recalcular los Retículos de Conceptos y sus Bases Stem asociadas en contextos dinámicos; es decir, en contextos que continuamente están cambiando. En la implementación actual, un cambio en el contexto implica tener que recalcular estos elementos para el nuevo contexto una vez modificado. Sería interesante descubrir métodos para reducir estos cálculos, puesto que es de suponer que una pequeña variación en el contexto, generará pequeñas variaciones en los retículos y en las bases Stem.

	\item En este trabajo, el conjunto de datos de prueba se ha parametrizado en función de su volumen. Sin embargo; un aumento en el volumen de datos no implica que las conciliaciones obtenidas sean más ricas, ni que se produzcan en un número.  Sería interesante introducir nuevas medidas del conjunto de datos de entrada para establecer un criterio de \emph{calidad}. Esto puede ser útil para estudiar diferentes criterios de aplicación en función de las características del conjunto de datos de entrada. Además, puede ser interesante para ofrecer comparativas acerca de los resultados obtenidos para diferentes datos de entrada.

	\item En la misma línea del punto anterior, sería interesante establecer un criterio de evaluación de los resultados obtenido. En este trabajo nos hemos ceñido a presentar el volumen de estos datos (en cuanto a medias, máximos y totales sobre el número de objetos, atributos, conceptos e implicaciones de los contextos obtenidos). Sería interesante conseguir una representación gráfica en forma de grafo, por ejemplo, que nos permita comparar distintos resultados en función del criterio seleccionado o del conjunto de datos de entrada.

\end{itemize}






\subsection{Implementación.}

En este apartado vamos a ver algunas líneas de trabajo futuro que están especialmente relacionadas con cuestiones técnicas de implementación. Algunas de estas cuestiones se introdujeron en las nota de implementación del capítulo~\ref{cap:capitulo6}; y otras se tratan de nuevas cuestiones que aún no se han tratado.

\begin{itemize}

	\item En el capítulo~\ref{cap:capitulo6} se comentaba la problemática de la ejecución del SMA cuando en la ejecución de éste participan un gran número de agentes. Recordemos que cada agente representa a un usuario del Sistema de Etiquetado. El hecho de que haya un gran número de agentes conviviendo en la plataforma se debe a que la restricción que se ha impuesto para que dos usuarios concilien su conocimiento (o no) es una restricción débil, permitiendo, de esta forma, que exista un gran número de usuarios implicados en este proceso. Además, cuando este número de conciliaciones es elevado, no es únicamente elevado el número de agentes, sino que también es elevado el número de interacciones entre estos agentes, los cuales pretenden conciliar su conocimiento con muchos otros agentes. Esto provoca un problema técnico por colapso en los recursos. Para solventar este problema, se propone una ejecución distribuida en varias máquinas, de forma que el agente Control, que se encarga de poner en marcha y gestionar todo el proceso, y que sea capaz de distribuir a los agentes en diferentes contenedores. La arquitectura de JADE (\cite{jade}) permite crear fácilmente esta estructura en la que, teniendo una única plataforma, existan diversos contenedores en los que se encuentren los agentes. La solución consistiría, básicamente, en que cada contenedor se encontrara en una máquina distinta, y se repartieran los agente proporcionalmente según estos contenedores. Esta solución no deja de ser una primera aproximación, pues si el volumen de datos del problema creciera exponencialmente, situación que podría ocurrir si se implantara este SMA en un Sistema de Etiquetado real (en este trabajo sólo se ha utilizado un conjunto muy pequeño de datos en comparación con el volumen de los sistemas reales); entonces también tendría que crecer mucho el número de máquinas que acogiesen a los contenedores pertinentes, llegando a ser inviable en ciertos casos.

	\item En la misma línea que el punto anterior, se podría establecer un mecanismo de reparto de carga dinámico entre un número fijo de contenedores, de forma que el (o los) agente(s) de control pudieran repartir a los usuarios del SMA en los diferentes contenedores según el volumen de carga computacional de cada uno de los usuarios en cada momento. Esta solución solventa el problema del crecimiento ilimitado del número de contenedores; sin embargo, tampoco es una solución definitiva, pues es posible que el contenedor oportuno se siga colapsando debido a una carga de trabajo demasiado grande y que no pueda asumir. Además, surge un nuevo problema debido al cuello de botella que se produce en la tarea de reparto de carga, y todos los problemas que derivan de éste: posible colapso, errores fatales en caso de que el agente muera y no sea capaz de recuperarse, etc.

	\item Sin ser incompatible con las soluciones anteriores, otra solución que se plantea es crear varios agentes de control, de forma que se reduzcan los efectos del cuello de botella de este agente, y además, solventar las consecuencias de posibles muertes de alguno de estos agentes, en la que el resto de agentes asumirían el trabajo del agente ya muerto, y el sistema podría continuar su ejecución normalmente.

	\item Paralelamente a la solución del reparto de carga dinámica, y no por ello incompatible con ésta, se podría llevar a cabo una solución en la que se limitara el número de conciliaciones que se producen en cada momento. Primeramente habría que establecer un número máximo de conciliaciones simultáneas, de forma que se garantice la buena ejecución del sistema, evitando posibles colapso por consumo total de los recursos disponibles Una vez hecho esto, existen varias estrategias para cumplir esta limitación. Pongamos dos ejemplos: sistema de pizarra, y agente distribuidor. La primera estrategia consistiría, \emph{a grosso modo}, en una pizarra accesible desde cualquier agente, de forma que todos ellos pudieran consultar la información allí escrita, y que además, todos pudieran modificar dicha información. De esta forma, cada agente, antes de iniciar una conciliación, debería consultar esta pizarra para decidir si es posible comenzar esta conciliación; y en caso de no ser posible, esperar hasta que pueda comenzar. La segunda estrategia consiste en establecer un agente encargado de dar permiso o negarlo a los usuarios que soliciten comenzar una conciliación; de forma que siempre se cumpla la limitación del número de conciliaciones simultáneas.

	\item Existen ocasiones en los que, durante la ejecución de los comportamientos del agente, se producen excepciones y su ejecución se aborta. Estas excepciones conllevan, generalmente, la muerte del agente. Se propone un sistema de copia de seguridad y restauración del agente en caso de que se produzcan estas excepciones. Una posible solución es capturar adecuadamente todas estas excepciones, y antes de que el agente muera, pueda guardar su estado y reiniciarse. En ciertos casos, quizás sea necesario que esta tarea se complemente con un agente restaurador encargado de esta misión.

	\item A lo largo de este trabajo se ha hablado de la solución propuesta como una función secuencial que, dado unos datos de entrada, devuelve unos resultados. En sistemas reales esta concepción no es viable, debido a que el gran volumen de datos y el incremento de éstos paulatinamente implica que la tarea probablemente nunca termine (excepto en aquellos casos que se imponga una restricción muy fuerte, y por tanto, los resultados obtenidos sean muy pobres). Una línea de trabajo interesante sería plantear este sistema con un funcionamiento atemporal, de forma que durante su ejecución produzca ciertos resultados, intentado priorizar aquellos resultados que a priori se consideren más importantes.

	\item Finalmente, y como se explicaba en la sección anterior, puede ser interesante estudiar en qué términos, un retículos (y sus implicaciones asociadas) cambian en función de pequeños cambios en el contexto, sin tener que recalcularlo todo de nuevo. Sería interesante implementar estas técnicas antes de aplicar el sisteman a un entorno dinámico al que se incorporen nuevos datos en cada instante.


\end{itemize}





\subsection{Aplicación.}

Finalmente, en esta sección vamos a ver algunas de las líneas de trabajo futuro que pueden ser interesantes para implantar este sistema en un Sistema de Etiquetado real.

\begin{itemize}

	\item A lo largo de todo este capítulo se han visto las diferencias entre el conjunto de datos utilizado y un conjunto de datos de un Sistema de Etiquetado real. La diferencia en cuanto a volúmenes de datos es abismal. Por tanto, sería interesante analizar los resultados obtenidos en un sisteman en el que los usuarios compartan muchos más enlaces y más atributos. Por ejemplo, sería muy interesante saber si, a partir de cierto umbral (de objetos o atributos compartidos, o cualquier otro), el tamaño de los contextos conciliados crece de forma exponencial (en lugar de crecer de forma lineal como ocurre en este trabajo). Para saber si esta circunstancia ocurre, no queda más remedio que llevar a cabo la ejecución con un volumen de datos mucho más grande.

	\item En la introducción de este trabajo se comentaban algunas de las principales motivaciones de este trabajo, que no son otras que establecer un conocimiento común entre usuarios para otros usos futuros, como navegación entre usuarios, búsquedas autocompletadas con la información semántica que otros usuarios puedan aportar, sugerencias de nuevos etiquetado, etc... Sería interesante aplicar alguna de estas ideas a los resultados conseguidos con este trabajo, para ver su verdadera utilidad y comparar su comportamiento frente a otras herramientas y utilidades que existen actualmente en el mercado.

	\item Como se remarca en \cite{algoritmo}, es necesario seguir trabajando en las contextualizaciones de grupos de usuario, para extraer conocimiento (semántico) a partir de éstas. Una extensión del algoritmo básico con el fin de encontrar ontologías consesuadas por todos los usuarios (o grupos amplios de ellos), debe ser una línea fundamental de trabajo desde el punto de vista de la aplicación semántica.

\end{itemize}






